\section{Experiments} % (fold)
\label{cha:experimental_setup}
\todo[inline]{Don't forget to cover details like sampling method, features (separate subsection?), difference in settings for each test and data set, etc.

ALSO: INCLUDE RESULTS!}

The previously elaborated theory on local NBNN exemplar model detection will be tested using a number of experiments to test it, show the effect of various variants, and to compare it with similar methods. First, The local NBNN part will be tested on the simpler task of classification. Next, the exemplar model detection is added onto the basic NBNN frame. The third experiment combines exemplar model detection with local NBNN, to create the full pipeline used in the remaining experiments.

In the fourth experiment, the effect of using different clustering algorithms is explored. Finally some experiments are performed that try to mitigate some inherently disadvantages of NBNN, such as Behmo's method\cite{behmo2010towards}.


\subsection{Features} % (fold)
\label{sec:features}

In all experiments, the image features are densely sampled, according to Boiman's\cite{boiman2008defense} observation that NBNN needs as many descriptors as possible. \todo{Check if explanation is done in NBNN section, refer to that}.
The basic feature that has been used is the much used scale-invariant feature transform (SIFT).\cite{lowe2004distinctive}

Applied to dense sampling, without the Difference of Gaussian based key point localization phase, the SIFT method simply consists of the generation of a descriptor at a given location and scale. The descriptor itself is defined by splitting the area around the sampled location into $4\times4$ subregions, that in turn are subdivided in $4\times4$ sample points. The sample points are weighted by a gaussian window around the central key point location. For each sample point, the gradient orientation and size is obtained, and the gradients are binned per subregion into an orientation histogram. Each having 8 bins, the $4\times4$ subregions make up a 128 dimensional vector. \todo{include image?}

Some experiments have been performed comparing variants of SIFT, including  RootSIFT\cite{arandjelovic2012three} and variants of colorSIFT\cite{vandeSande2010colorSIFT}.

\todo[inline]{Explain each shortly.}
% section features (end)

\subsection{PASCAL VOC Data Set} % (fold)

\label{sec:voc_data_set}
The Visual Object Classes (VOC) 2007 challenge of the PASCAL network \cite{pascal-voc-2007} provides a popular data set annotated for image detection\todo[fancyline]{references}. The data set consists of 20 object classes,\todo{show these?} on a total of 9,963 images containing 24,640 annotated objects. The images are all taken from Flicker, and show a large variety of image quality and intra-class variety of objects. The data set is subdivided into 50\% test set, 25\% training set and 25\% validation set, with approximately equal distribution of class object distribution over the sets.

The VOC 2007 dataset is partly annotated for class segmentation, 844 images subdivided in the same way as the full set. Its test set is used as the basis for some of the smaller experiments.

\todo[inline]{Needs more elaboration, or not really?}
% section voc_data_set (end)

\subsection{TUDmotorbikes Data Set} % (fold)
\label{sec:tudmotorbikes_data_set}

\todo{Explain how Becker uses it, look for reference}
% section tudmotorbikes_data_set (end)

\subsection{Caltech101 Data Set} % (fold)
\label{sec:caltech101_data_set}
\todo[inline,color=red]{Not sure if used.}
% section caltech101_data_set (end)

\subsection{Graz01 Data Set} % (fold)
\label{sec:graz01_data_set}
\todo[inline,color=red]{Not sure if used.}
% section graz01_data_set (end)

\subsection{NBNN Classification} % (fold)
\label{sec:nbnn-cls}
\todo[inline,color=red]{This section only if the tests succeed. Most of the method is already in the NBNN section.}

% section nbnn-cls (end)

\subsection{Exemplar-NBNN Detection} % (fold)
\label{sec:nbnn_detection}
The detection experiment is more advanced than image classification. In the first place, not only a class should be determined, but a rectangular bounding box that indicates the object's location within the image. For exemplar based detection, these bounding boxes are generated from exemplars, which means that these have to be stored for all descriptors in the training images. Secondly, even though the object's background can supply information about the object's class, it should be viewed separately from the object itself, because it is needed to create a sharp boundary between object and background. Finally, in the detection task it is possible for an image to have multiple objects, of the same or different classes. Furthermore, these objects might overlap. This makes detection a more subtle task than classification, and quite some changes of the classification are needed to get a good detection algorithm.

For exemplar-NBNN detection, the ground-truth bounding boxes of the training images is used to create exemplars of the descriptors. Only descriptors sampled from the object itself can be used for the NN index of the object's class. The bounding box can be used to define this boundary, but when available, a segmentation ground truth can also be used as a basis, because bounding boxes tend to include quite some background area too. \todo{image?}

An exemplar is defined as a 4D vector of the relative width and height of the object's bounding box with respect to the descriptor's scale, and the relative horizontal and vertical position of this descriptor within the bounding box. In this way a new bounding box (called a hypothesis) can be reconstructed from a new descriptor location and scale.

Descriptors in the training images that fall outside the objects are regarded as background, and are added to a separate background class.

For each test image and each class, descriptors are densely sampled, and the distance of each descriptor towards the current class and towards the background class is measured using approximate NN. Now, all descriptors closer to the class than to the background are seen as potential detections of an object. From these descriptors, detection hypotheses are calculated (using their NN-descriptor's exemplar).

This array of hypotheses is clustered to find likely detections. The similarity measure used to find clusters is based on the area of overlap ($AO$) between two hypotheses:
\begin{equation}
    AO(H_a, H_b)= \frac{|H_a\cap H_b|}{|H_a\cup H_b|}
\end{equation}

The resulting detections can be ranked by the number of hypotheses that support it, or by the average relative distance between foreground and background NN of the descriptors on which the hypotheses were based.

\subsubsection{NBNN Detection Using Single Link Clustering} % (fold)
\label{sub:nbnn_detection_using_single_link_clustering}

\todo[inline]{Write a short piece on single link clustering, the parameters and stuff. Refer to Becker's paper}

% subsection nbnn_detection_using_single_link_clustering (end)

\subsubsection{NBNN Detection Using Quickshift Clustering} % (fold)
\label{sub:nbnn_detection_using_quickshift_clustering}

\todo[inline]{Write a short piece on quick shift clustering, the parameters and stuff}

% subsection nbnn_detection_using_quickshift_clustering (end)

\subsubsection{Exemplar-NBNN Results} % (fold)
\label{sub:exemplar_nbnn_results}
\todo[inline]{Do results}
\begin{figure}[hbt]
    \centering
    \missingfigure[figwidth=0.8\textwidth]{Result graph}
\end{figure}

% subsection exemplar_nbnn_results (end)

% section nbnn_detection (end)

\subsection{Local Exemplar-NBNN Detection} % (fold)
\label{sec:local_nbnn_detection}
A downside of the exemplar-NBNN method is the descriptor aliasing problem explained in Section \ref{sec:descriptor_aliasing}. This can be solved by taking the $k$ of $k$NN to be greater than 1. This means that the $k$ closest neighbors over all classes (the object class and the background class) are taken into account when constructing detection hypotheses. Within these $k$ nearest neighbors, the ones belonging to the object class that are closer than any neighbor in the background class, are transformed into detection hypotheses, avoiding the risk of disregarding very similar, although not most similar, exemplars when clustering.

\todo[inline]{Previous is implemented, coming part will hopefully be so.}

Another disadvantage of exemplar-NBNN is it returning many false positive detections for images not having any objects of the current object class. The reason for this is obvious, as all descriptors closer to the class than to the background will be regarded as hypotheses, and therefore even images without objects get reasonably well ranked detections. This problem gets larger as the data sets contains more object classes.

A solution for this is to not only compare the current object class with the background class, but to compare it with all other classes, to see what each descriptor in the test image looks most like. This results in a hypothesis selection step that chooses only descriptors that are closer to the current class than to any other.

This however would create another problem not present in the original approach. Some descriptors could be an indication for multiple classes, because certain parts of objects are quite similar. While the original exemplar-NBNN approach allows for this, regarding each class independently, this multi-class approach prevents this. Think of the similarity of a bicycle wheel with that of a motorbike or a car. To disregard all but one of these classes might cause very little evidence for most classes in an image, giving less stable detections. This reminds of Boiman's argument that much evidence is vital for the NBNN method, because the Naive Bayes assumption is only met towards infinity and there is no training phase to compensate for that.\cite{boiman2008defense}

At the same time, the goal to compare all classes simultaneously is similar to McCann's formulation of local NBNN's query.\cite{mccann2012local} (\emph{cf.} Section \ref{sec:local_nbnn}). Merging all class indexes into one, and taking into account not only the first per class, but the $k$ closest neighbors overall prevents having too many false positive results, while keeping the possibility of a descriptor to be used for a hypothesis for multiple classes like in the original problem.

As a bonus, local NBNN for detection also incorporates a way to prevent the aliasing problem. Among the $k$ closest neighbors, there might be multiple ones from the same class. Instead of disregarding these neighbors like local NBNN does, they can be taken into account by creating hypotheses for all non-background nearest neighbors.

\todo[inline]{Some more?? And Results}

\begin{figure}[hbt]
    \centering
    \missingfigure[figwidth=0.8\textwidth]{Result graph}
\end{figure}

% section local_nbnn_detection (end)

\subsection{Training Weighted Distances} % (fold)
\label{sec:training_weighted_distances}

In image classification, the classes are generally quite well balanced. The amount of images in every class is usually approximately the same and all image are usually of the same size, making the assumption of a uniform prior hold. Therefore the natural distribution of descriptors in feature-space can be assumed to be equally sampled in every class. This makes it acceptable to use a learning method like optimal NBNN\cite{behmo2010towards} or \ldots \todo{put Wang's method here}\cite{wang2011improved} to tune the likelihood of classes to the local density in feature space to be equal for all classes.

In object detection, the sampling rate will not be equal over classes, especially the background class will have a larger sampling rate, simply because it will occur in virtually all images. The equal priors assumption therefore does not hold. This flaw is mitigated by the fact that a higher number of sampled descriptors also tends to make the feature space for that class more dense, and more likely to be the nearest neighbor.

The risk however is that the estimation of the feature space may differ largely per class. Classes with a large intra-class variety of descriptors, but with generally small objects will be sampled much sparser than classes with less descriptor variety and larger objects. Learning parameters to tune the feature space density might therefore result in overfitting for sparsely sampled classes or classes with a very high intra-class diversity.

This experiment will test this hypothesis using Behmo's optimal NBNN linear program to train per-class parameters on sampled images.

\todo[inline]{more detail about implementation of Behmo. Perhaps put the first part either to conclusion, or to theory?}

\begin{figure}[hbt]
    \centering
    \missingfigure[figwidth=0.8\textwidth]{Result graph}
\end{figure}

% section training_weighted_distances (end)

% chapter experimental_setup (end)