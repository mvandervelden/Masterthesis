\section{Introduction} % (fold)
\label{cha:introduction}

\todo[inline]{At the end, review the introduction to see whether the emphasis is correct: should be on the benefits of NBNN, and exemplar model detection..}

Finding objects in images is a main topic in the research area of computer vision. Most methods for finding objects are designed specifically for certain subtopics, such as retrieving one type of objects only, categorizing the scene of the image, or discerning foreground objects from the background. For each of these subtopics, the object finding task is modeled in a certain way. Three very common models are image classification, image segmentation, and object detection.

\JanTodo{Motiveer buiten CV: Globaler nut van obj.det.}

In image classification (Figure~\ref{fig:classification}), the object finding task is represented as the task of predicting the class of a whole image. The prediction is some measure of how likely it is for an image to belong to a certain class. This task is useful when the image as a whole is of importance, for example when a user is looking for images of a certain topic.

Image segmentation is different from image classification, because for each pixel in the image, a class label has to be found.(Figure~\ref{fig:segmentation}) This task is more complex than classification, because there is less information available for a small patch of the image than for the image as a whole. Therefore, the context of each segment becomes more important for a good classification of objects. Image segmentation might be useful when trying to find the distinction between foreground and background, for example.

Object detection (Figure~\ref{fig:detection}) is similar to both image classification and segmentation, and lies somewhere in between these tasks. Detection is the task of pinpointing areas on an image where objects are, and of which class this object is. Detection is more specific than classification, because the objective is not only to give a class label, but also an indication of the object's location. This indication is not as specific however as in the segmentation task, because the goal is not to define a class for all pixels in the images, but only for the foreground objects. the indication of the object's location can be given in a number of ways, but the most common one is to give a rectangular bounding box that envelops the object \cite{pascal-voc-2007}. Object detection is useful when you are interested in only specific parts of the image, for example in tasks like face detection.

\begin{figure}[hbt]
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{000032}
        \caption{Classification}
        \label{fig:classification}
    \end{subfigure}%
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{000032-det}
            \caption{Detection}
            \label{fig:detection}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{000032-clsseg}
            \caption{Class-segmentation}
            \label{fig:segmentation}
            \end{subfigure}
    \caption{Three Computer Vision tasks for the same image. If the question is to find persons and airplanes, in a classification task \textbf{(a)} it would be enough to classify the image as a whole as containing both classes. In a detection task \textbf{(b)} bounding boxes need to be given that neatly envelop the objects and have the correct class label. In a class-segmentation task \textbf{(c)}, every pixel should be labeled correctly ``airplane'', ``person'' or ``background'' (transparent in this case). Note that this segmentation image has a blank label for areas that are either on the boundary between different classes, or difficult to classify (at the left side of the image). \cite{pascal-voc-2007}}
    \label{fig:clsdetseg}
\end{figure}

For image classification, recently the Naive Bayes Nearest Neighbor (NBNN) \cite{boiman2008defense} approach has gained popularity. \cite{becker2012codebook, behmo2010towards, mccann2012local, timofte2012iterative, tuytelaars2011nbnn, wang2011improved, zhang2010random} Boiman \emph{et al.} apply the simple nature of nearest-neighbor classification to build a state-of-the-art image classification method. They show that a Nearest-Neighbor based approach for image classification has two main advantages.

\todo[inline]{explain about image to class distance and quantization, also add a simple image that shows these things -> only SHORTLY because it is explained in the dedicated section}.
\JanTodo{Explain Becker}

McCann \& Lowe \cite{mccann2012local} have come up with an adaptation of NBNN which uses more than one nearest neighbor to find object-to-class distances to multiple classes at once, making the process more efficient and the performance better. 

In this thesis I will explore the possibilities of extending the NBNN method from image classification to object detection. I combine McCann \& Lowe's local-NBNN based object-to-class distance estimation with exemplar-based object detection \cite{becker2012codebook, chum2007exemplar}. To do this, each object descriptor taken during training is regarded as an exemplar: it refers to a certain part of the object it was sampled from. In this way, bounding box hypotheses can be made from descriptors in a test image and their nearest neighbor exemplars. These hypotheses can be clustered to form detections. Single link agglomerative clustering is compared in this regard with quickshift mode finding clustering.

The tests are performed on both a composed dataset of motorbike images \cite{becker2012codebook, fritz2005integrating}, and on the challenging VOC2007 object detection task \cite{pascal-voc-2007}.

\todo[inline]{Make sure all experiments are mentioned and shortly explained in here, and it is made clear what the benefit of the method is, before the next (last) section.}

Section~\ref{cha:related_work} gives an overview of related work on the various parts of this task. In Section~\ref{cha:naive_bayes_nearest_neighbor} I will discuss the details of the NBNN method, and the assumptions under which it works. In Section~\ref{cha:object_detection} the theory behind exemplar-based modeling will be explained. The link between the two methods will be made in Section~\ref{cha:linking}. In Section~\ref{cha:experimental_setup} the experiments will be elaborated, after which the results are given. In Section~\ref{cha:analysis_of_results} these results are discussed and analyzed. Finally, in Section~\ref{cha:conclusion} conclusions will be drawn and discussed.

% section introduction (end)