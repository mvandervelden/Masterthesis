\chapter{Object Detection Using Exemplar Models} % (fold)
\label{sec:object_detection}

\begin{figure}[hbt]
    \centering
    \missingfigure[figwidth=0.8\textwidth]{Show images of the idea comparing the methods discussed}
\end{figure}

The most intuitive way of thinking about object detection is probably to apply image classification at various windows within the image instead of on the image as a whole. This involves iterating over possible window locations, sizes and aspect ratios for the whole image, and determining the likelihood of each window of representing an object. This sliding window approach marks early detection methods.\cite{viola2004robust} The applicability of this approach however is fairly limited, because of the large number of possible windows to check. Therefore, lot of methods find a way to make this window search more efficient. Viola and Jones\cite{viola2004robust} propose a cascade approach, where a very simple classification method is used on the full set of hypotheses for bounding boxes in order to cast most of them away early. On the difficult hypotheses a more sophisticated classification is done to narrow down the search more and more, each step using a better, and much slower classification algorithm. In contrast, Efficient Sub-window Search methods\cite{ lampert2008beyond, yeh2009fast, pedersoli2011coarse, behmo2010towards} model the problem into a branch-and-bound search method. They recursively split the window in two, find the response for the class on the current scale, and continue with the most promising leaf. When the response of both windows after a split is lower than the one above, the correct window is assumed to be on the above level.

Another approach that recently gained more attention is that of detection by segmentation.\cite{van2011segmentation,zhang2010free} These methods rely on the fact that segmentation methods are meant to subdivide the image into segments that represent a semantic unity, like parts of objects or full objects. The resulting segments can be used as hypotheses for detecting objects. This means the amount of possible windows can be reduced heavily. Van de Sande \emph{et al.}\cite{van2011segmentation} use a hierarchical segmentation algorithm to make the detection scale invariant, and train discriminatively by focusing on hard examples. Zhang \emph{et al.}\cite{zhang2010free} do not explicitly segment the image, but just like many segmentation algorithms they do look for edges that enclose an object as a restraint for selecting it as a possible detection.

Part-based models form a different approach on effectively finding hypothesis windows for objects.\cite{felzenszwalb2010object} These methods learn object models based on a combination and spatial organization of a number of designated, but unlabeled, parts. These parts are learned as a hidden variable during training, being groups of features reoccurring in the same formation in a certain area of bounding boxes of a class. Furthermore, the difference in scale between the full object window (the root) and its parts is fixed. In comparison with sliding-window approaches, this means a restriction in the number of possibilities for detection of objects. The relative scale of the parts should comply with that of the root scale. \todo{need to cite these, perhaps briefly mention them before...?}

\section{Exemplar models} % (fold)
\label{sub:exemplar_models}

Related to part-based models are exemplar models. \cite{leibe2004combined, chum2007exemplar} Exemplar models do not explicitly model object parts, but they do something similar implicitly on the feature level. In this approach, for each object feature found during training, an exemplar is stored. The exemplar represents the size and location of the bounding box relative to the feature. The exemplars are aggregated into part models\cite{leibe2004combined} or visual words\cite{chum2007exemplar}. In this way a class is modeled by a set of exemplars that have a high probability of occurring in a certain location and at a certain scale of the image.

At test time, each feature found in the test image is matched with the exemplars stored, and from this combination of the location and scale of the feature found, and the exemplar it is matched with, a hypothesis can be formed for the object's location in the test image. This means that each feature in the test image gets a vote, weighted by the quality of its match, for a bounding box. These hypotheses can be clustered into detection windows. Experiments\cite{vedaldi2009multiple} show that this method performs well too as a first step in a cascade setting.

In more detail, 

\todo[inline,color=green]{part on why I choose exemplar models, little more explanation of theory of Chum to link it to the next section}
% subsection exemplar_models (end)

\section{Clustering Algorithms} % (fold)
\label{sub:clustering_algorithms}

Clustering is a way to find classes of items without having a predefined idea of what these classes represent. It is a form of unsupervised learning, meaning that there are no ground-truth classes available. Usually the parameters of the classes are unknown, and often also the number of classes is not predefined. Clustering algorithms can be applied to all all kinds of situations.

In exemplar-model detection, hypotheses of bounding boxes need to be clustered into detections. These detections represent the classes, which are inherently unknown, and depend fully on the image at hand, and the hypotheses that have been derived from it. The number of objects in the image is unknown, so the number of clusters should not be fixed.

A number of algorithms exist that can be used to cluster objects. A well known algorithm is called k-means clustering. This algorithm divides all objects in a pre-defined number of $k$ clusters, minimizing the sum of squared distances of all objects within each separate cluster. This is calculated iteratively by assigning each object to the cluster with the nearest cluster center, and then setting the cluster's center at the mean position of all its members. One important downside of this algorithm for the detection problem is that we do not have an indication of the number of clusters wanted. Therefore, other algorithms can be considered.

\todo[inline]{Include an image comparing the clustering algorithms mentioned: see diff between aggl. clustering and quickshift}

\subsection{Agglomerative Clustering} % (fold)
\label{sub:agglomerative_clustering}
It is possible to view a clustering clustering algorithm as a tree, where the leaves represent the objects to be clustered. If the pairwise distances between all objects are known, the leaves can be joined into clusters iteratively, each time merging the two closest objects into a cluster. When these clusters are again clustered based on distance, merging will continue until there is only one single cluster left. Afterwards, this tree could be split into clusters by cutting branches that exceed a certain threshold distance. This clustering algorithm is called Agglomerative clustering. It is a subtype of hierarchical clustering, other hierarchical algorithms not being agglomerative, but divisive, starting with one single cluster.

There is some variety in the ways to merge leaves into clusters. Single link clustering means that the minimum distance between members of each cluster is the basis of further clustering, complete linkage and mean linkage clustering take the maximum distance and the mean distance, respectively.

\todo[inline]{More explanation and some image}

% subsubsection agglomerative_clustering (end)

\subsection{Mode finding algorithms} % (fold)
\label{sub:mode_finding_algorithms}
\todo[inline]{mean-shift,Quickshift, difference with hierarchical clustering, benefits, image}


% subsubsection mode_finding_algorithms (end)

% subsection clustering_algorithms (end)

% section object_detection (end)
